{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Levenshtein\n",
    "\n",
    "df = pd.read_csv(r'D:\\Users\\peter\\PythonProjects\\PandasTest\\data\\Week 05 Sun.csv')\n",
    "#df.info()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217 entries, 0 to 216\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                                                        Non-Null Count  Dtype         \n",
      "---  ------                                                                        --------------  -----         \n",
      " 0   Is_Duplicate                                                                  217 non-null    bool          \n",
      " 1   Submission ID                                                                 217 non-null    object        \n",
      " 2   Respondent ID                                                                 217 non-null    object        \n",
      " 3   can_id                                                                        213 non-null    object        \n",
      " 4   surveyid                                                                      0 non-null      object        \n",
      " 5   Name                                                                          176 non-null    object        \n",
      " 6   Email                                                                         171 non-null    object        \n",
      " 7   Response_Count                                                                217 non-null    object        \n",
      " 8   Submitted at                                                                  217 non-null    datetime64[ns]\n",
      " 9   More Info (1)                                                                 47 non-null     object        \n",
      " 10  Additional ideas for your comment (1)                                         112 non-null    object        \n",
      " 11  Did you send a comment to your Senator about SB 5955?                         143 non-null    object        \n",
      " 12  Run into issues with SB 5955 or need to elaborate?                            5 non-null      object        \n",
      " 13  More Info (2)                                                                 40 non-null     object        \n",
      " 14  Additional ideas for your comment (2)                                         111 non-null    object        \n",
      " 15  Did you send a comment to your two Representatives about HB 2156?             139 non-null    object        \n",
      " 16  Run into issues with HB 2156 or need to elaborate?                            4 non-null      object        \n",
      " 17  More Info (3)                                                                 40 non-null     object        \n",
      " 18  Additional ideas for your comment (3)                                         105 non-null    object        \n",
      " 19  Did you send a comment to your two Representatives about HB 1185?             133 non-null    object        \n",
      " 20  Run into issues with HB 1185 or need to elaborate?                            5 non-null      object        \n",
      " 21  More Info (4)                                                                 29 non-null     object        \n",
      " 22  Email link not work for you? (1)                                              72 non-null     object        \n",
      " 23  Did you email the 58 members of the House about HB 1445??                     127 non-null    object        \n",
      " 24  Run into issues with HB 1445? or need to elaborate?                           13 non-null     object        \n",
      " 25  More Info (5)                                                                 34 non-null     object        \n",
      " 26  Additional ideas for your comment (4)                                         94 non-null     object        \n",
      " 27  Did you send a comment to your two Representatives about HB 1513?             122 non-null    object        \n",
      " 28  Run into issues with HB 1513 or need to elaborate?                            14 non-null     object        \n",
      " 29  More Info (6)                                                                 42 non-null     object        \n",
      " 30  Email link not work for you? (2)                                              78 non-null     object        \n",
      " 31  Did you email the 16 committee members about HB&nbsp;2089?                    120 non-null    object        \n",
      " 32  Run into issues with HB&nbsp;2089 or need to elaborate?                       10 non-null     object        \n",
      " 33  More Info (7)                                                                 27 non-null     object        \n",
      " 34  Email link not work for you? (3)                                              65 non-null     object        \n",
      " 35  Did you email the 24 committee members about SB 5950?                         123 non-null    object        \n",
      " 36  Run into issues with SB 5950 or need to elaborate?                            8 non-null      object        \n",
      " 37  More Info (8)                                                                 37 non-null     object        \n",
      " 38  Email link not work for you? (4)                                              63 non-null     object        \n",
      " 39  Did you email the 24 committee members about SB 5949?                         116 non-null    object        \n",
      " 40  Run into issues with SB 5949 or need to elaborate?                            10 non-null     object        \n",
      " 41  Awesome, you did it! Thank you and please let us know if you had any issues.  15 non-null     object        \n",
      "dtypes: bool(1), datetime64[ns](1), object(40)\n",
      "memory usage: 69.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convert the column to dtype 'datatime'\n",
    "df['Submitted at'] = pd.to_datetime(df['Submitted at'])\n",
    "\n",
    "# Convert the column to dtype 'object' to handle strings properly\n",
    "df['surveyid'] = df['surveyid'].astype('object')\n",
    "\n",
    "# Replace 'Untitled multiple choice field' with 'More Info' in all column names\n",
    "df.columns = df.columns.str.replace(r'Untitled multiple choice field', 'More Info')\n",
    "#df\n",
    "\n",
    "# Remove the 'Submitted at' column...\n",
    "column = df.pop('Submitted at')\n",
    "\n",
    "# Insert 'Submitted at' column at index position 6\n",
    "df.insert(6, 'Submitted at', column)\n",
    "\n",
    "# Insert two new columns that we need later\n",
    "df.insert(loc=6, column='Response_Count', value='0')\n",
    "df.insert(loc=0, column='Is_Duplicate', value=False)\n",
    "\n",
    "df.info()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows when 'can_id' is NaN\n",
    "\n",
    "df.dropna(subset=['can_id'], inplace=True)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'surveyid' with the specified string\n",
    "# How do we pass this string into the DataFrame script?\n",
    "\n",
    "df['surveyid'] = df['surveyid'].fillna('Week 05 Sun')\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email validation pattern\n",
    "email_pattern = re.compile(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\")\n",
    "\n",
    "# Common email domains\n",
    "common_domains = {\n",
    "    \"350seattle.org\": \"350seattle.org\",\n",
    "    \"aol.com\": \"aol.com\",\n",
    "    \"comcast.net\": \"comcast.net\",\n",
    "    \"duck.com\": \"duck.com\",\n",
    "    \"fastmail.com\": \"fastmail.com\",\n",
    "    \"frontier.com\": \"frontier.com\",\n",
    "    \"gmail.com\": \"gmail.com\",\n",
    "    \"hotmail.com\": \"hotmail.com\",\n",
    "    \"icloud.com\": \"icloud.com\",\n",
    "    \"mac.com\": \"mac.com\",\n",
    "    \"me.com\": \"me.com\",\n",
    "    \"msn.com\": \"msn.com\",\n",
    "    \"outlook.com\": \"outlook.com\",\n",
    "    \"pobox.com\": \"pobox.com\",\n",
    "    \"proton.me\": \"proton.me\",\n",
    "    \"protonmail.com\": \"protonmail.com\",\n",
    "    \"uw.edu\": \"uw.edu\",\n",
    "    \"yahoo.com\": \"yahoo.com\"\n",
    "}\n",
    "\n",
    "# Common TLD misspellings\n",
    "tld_corrections = {\n",
    "    'com': ['copm', 'co', 'cpm', 'comm', 'copm'],\n",
    "    'org': ['ogr', 'orgg', 'or'],\n",
    "    'net': ['nett', 'ne', 'nte'],\n",
    "    'gov': ['gvo', 'govv', 'go'],\n",
    "    'edu': ['ed', 'edd', 'eud']\n",
    "}\n",
    "\n",
    "# Function to correct common TLD misspellings\n",
    "def correct_tld(domain):\n",
    "    tld = domain.split('.')[-1]\n",
    "    base_domain = '.'.join(domain.split('.')[:-1])\n",
    "    for correct_tld, misspellings in tld_corrections.items():\n",
    "        if tld in misspellings:\n",
    "            return f\"{base_domain}.{correct_tld}\"\n",
    "    return domain\n",
    "\n",
    "# Function to validate and correct email addresses\n",
    "def validate_and_correct_email(email):\n",
    "    if isinstance(email, str) and email_pattern.match(email):\n",
    "        domain = email.split('@')[1]\n",
    "        corrected_domain = correct_tld(domain)\n",
    "        if corrected_domain in common_domains:\n",
    "            return email.split('@')[0] + '@' + corrected_domain\n",
    "        else:\n",
    "            # Find the closest match if the domain is incorrect\n",
    "            corrected_domain = min(common_domains.keys(), key=lambda k: Levenshtein.distance(corrected_domain, k))\n",
    "            return email.split('@')[0] + '@' + corrected_domain\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Convert all email values to strings, replacing NaN with empty string\n",
    "df['Email'] = df['Email'].astype(str).fillna('')\n",
    "\n",
    "# Validate and correct email addresses\n",
    "df['Email'] = df['Email'].apply(validate_and_correct_email)\n",
    "\n",
    "#df.info()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup df to compare and fill empty 'Email' and 'Name' values based on 'Respondent ID'\n",
    "\n",
    "# Identify duplicates in 'Respondent ID' with 'True' in 'Is_Duplicate' column\n",
    "df['Is_Duplicate'] = df['Respondent ID'].duplicated(keep=False)\n",
    "\n",
    "# Sort by 'Respondent ID' and reset index\n",
    "sorted_df = df.sort_values(by=['Respondent ID'], ascending=[True])\n",
    "sorted_df = sorted_df.reset_index(drop=True) # Reset index\n",
    "\n",
    "df = sorted_df\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12880\\1744984796.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  RespondentID_groups = grouped.apply(lambda x: fill_columns(x.reset_index(drop=True))).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Identify the duplicates for 'Respondent ID'\n",
    "duplicate_respondents = df[df.duplicated('Respondent ID', keep=False)]\n",
    "\n",
    "# Group by 'Respondent ID' to handle each set of duplicates\n",
    "grouped = duplicate_respondents.groupby('Respondent ID')\n",
    "\n",
    "# Function to fill empty values in the 'Email' and 'Name' columns for each group\n",
    "def fill_columns(group):\n",
    "    group = group.copy()  # Avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Find non-NaN values if they exist\n",
    "    non_nan_email = group['Email'].dropna().iloc[0] if not group['Email'].dropna().empty else None\n",
    "    non_nan_name = group['Name'].dropna().iloc[0] if not group['Name'].dropna().empty else None\n",
    "    \n",
    "    # Fill NaN values with non-NaN values found within the group\n",
    "    if non_nan_email:\n",
    "        group['Email'] = group['Email'].fillna(non_nan_email)\n",
    "    if non_nan_name:\n",
    "        group['Name'] = group['Name'].fillna(non_nan_name)\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group and reset the index\n",
    "RespondentID_groups = grouped.apply(lambda x: fill_columns(x.reset_index(drop=True))).reset_index(drop=True)\n",
    "\n",
    "# Combine the manipulated groups with the original DataFrame\n",
    "# First, drop the rows that were manipulated from the original DataFrame\n",
    "df_non_duplicates = df[~df['Respondent ID'].isin(RespondentID_groups['Respondent ID'])]\n",
    "\n",
    "# Concatenate the manipulated groups with the non-duplicate rows\n",
    "final_df = pd.concat([df_non_duplicates, RespondentID_groups]).sort_values(by='Respondent ID').reset_index(drop=True)\n",
    "\n",
    "df = final_df\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup df to compare and fill empty 'Email' and 'Name' values based on 'can_id'\n",
    "\n",
    "# Identify duplicates in 'can_id' with 'True' in 'Is_Duplicate' column\n",
    "df['Is_Duplicate'] = df['can_id'].duplicated(keep=False)\n",
    "\n",
    "# Sort by 'can_id' and reset index\n",
    "sorted_df = df.sort_values(by=['can_id'], ascending=[True])\n",
    "sorted_df = sorted_df.reset_index(drop=True) # Reset index\n",
    "\n",
    "df = sorted_df\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12880\\3683480017.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  can_id_groups_filled = can_id_groups.apply(lambda x: fill_columns(x.reset_index(drop=True))).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Identify the duplicates for 'can_id'\n",
    "duplicate_candidates = df[df.duplicated('can_id', keep=False)]\n",
    "\n",
    "# Group by 'can_id' to handle each set of duplicates\n",
    "can_id_groups = duplicate_candidates.groupby('can_id')\n",
    "\n",
    "# Function to fill 'Email' and 'Name' columns for each group\n",
    "def fill_columns(group):\n",
    "    group = group.copy()  # Avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Find non-NaN values if they exist\n",
    "    non_nan_email = group['Email'].dropna().unique()\n",
    "    non_nan_name = group['Name'].dropna().unique()\n",
    "    \n",
    "    # Check for the unique non-NaN values for 'Email' or 'Name'\n",
    "    if len(non_nan_email) == 1 and len(non_nan_name) == 1:\n",
    "        group['Email'] = group['Email'].fillna(non_nan_email[0])\n",
    "        group['Name'] = group['Name'].fillna(non_nan_name[0])\n",
    "\n",
    "    elif len(non_nan_email) == 1 and len(non_nan_name) == 0:\n",
    "        group['Email'] = group['Email'].fillna(non_nan_email[0])\n",
    "\n",
    "    elif len(non_nan_email) == 0 and len(non_nan_name) == 1:\n",
    "        group['Name'] = group['Name'].fillna(non_nan_name[0])\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group and reset the index\n",
    "can_id_groups_filled = can_id_groups.apply(lambda x: fill_columns(x.reset_index(drop=True))).reset_index(drop=True)\n",
    "\n",
    "# Combine the filled groups with the original DataFrame\n",
    "# First, drop the rows that were manipulated from the original DataFrame\n",
    "df_non_duplicates = df[~df['can_id'].isin(can_id_groups_filled['can_id'])]\n",
    "\n",
    "# Concatenate the filled groups with the non-duplicate rows\n",
    "final_df = pd.concat([df_non_duplicates, can_id_groups_filled]).sort_values(by='can_id').reset_index(drop=True)\n",
    "\n",
    "df = final_df\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fillna to replace the remaining NaN 'Email' values with 'can_id'\n",
    "df['Email'] = df['Email'].fillna(df['can_id'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup df for comparing and updating empty column values for duplicate rows\n",
    "\n",
    "# Identify duplicates in 'can_id' with 'True' in 'Is_Duplicate' column\n",
    "df['Is_Duplicate'] = df['Email'].duplicated(keep=False)\n",
    "\n",
    "# Sort by 'Email' and 'Submitted at' in ascending order\n",
    "sorted_df = df.sort_values(by=['Email', 'Submitted at'], ascending=[True, True])\n",
    "\n",
    "sorted_df = sorted_df.reset_index(drop=True) # Reset index\n",
    "df = sorted_df\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and update empty column values for duplicate rows so that we retain all action taker's entered values\n",
    "# Then drop the rows that are unneeded duplicates\n",
    "\n",
    "indices_to_drop = []\n",
    "\n",
    "for x in range(len(df) - 1):  # Iterate until the second last row\n",
    "\tif (df.loc[x, 'Email'] == df.loc[x + 1, 'Email']):\n",
    "\n",
    "\t\t# Iterate over each column starting from the 10th column (index 9 since indexing is zero-based)\n",
    "\t\tfor col in df.columns[9:]:\n",
    "\t\t\tif pd.isna(df.at[x+1, col]):  # Check if the next row's value is empty\n",
    "\t\t\t\tdf.at[x+1, col] = df.at[x, col]  # Set the value to the current row's value\n",
    "\t\n",
    "\t\tindices_to_drop.append(x)\n",
    "\t\n",
    "df = df.drop(indices_to_drop)\n",
    "\n",
    "df = df.reset_index(drop=True) # Reset index\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting in the 9th column, count the number of non-NaN values in each row and store in 'Response_Count'\n",
    "# However, do NOT count values in the UX columns\n",
    "# 'Response_Count' quantifies each action taker's level of engagement at the survey level\n",
    "# NOTE: We should NOT include rows of data in certain analyses if 'Response_Count' == 0\n",
    "\n",
    "# List of strings to exclude columns\n",
    "exclude_strings = ['More Info', 'Additional ideas for your comment', 'Email link not work for you?']\n",
    "\n",
    "# Create a mask for columns to exclude\n",
    "exclude_mask = df.columns.str.contains('|'.join(exclude_strings))\n",
    "\n",
    "# Create a mask for columns to include (starting from the 10th column, index 9)\n",
    "include_mask = ~exclude_mask & (np.arange(len(df.columns)) >= 9)\n",
    "\n",
    "# Count non-NaN values in each row for the included columns and store in 'Response_Count'\n",
    "df['Response_Count'] = df.loc[:, include_mask].notna().sum(axis=1)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cleanup of unneeded column\n",
    "df = df.drop('Is_Duplicate', axis=1)\n",
    "\n",
    "# Define file path\n",
    "# csv_path = r'D:\\Users\\peter\\PythonProjects\\PandasTest\\data\\Week 05 Sun_cleaned.csv'\n",
    "\n",
    "# Write DataFrame to CSV file\n",
    "# df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute columns: Index(['Response_Count', 'Submitted at', 'More Info (1)',\n",
      "       'Additional ideas for your comment (1)',\n",
      "       'Did you send a comment to your Senator about SB 5955?',\n",
      "       'Run into issues with SB 5955 or need to elaborate?', 'More Info (2)',\n",
      "       'Additional ideas for your comment (2)',\n",
      "       'Did you send a comment to your two Representatives about HB 2156?',\n",
      "       'Run into issues with HB 2156 or need to elaborate?', 'More Info (3)',\n",
      "       'Additional ideas for your comment (3)',\n",
      "       'Did you send a comment to your two Representatives about HB 1185?',\n",
      "       'Run into issues with HB 1185 or need to elaborate?', 'More Info (4)',\n",
      "       'Email link not work for you? (1)',\n",
      "       'Did you email the 58 members of the House about HB 1445??',\n",
      "       'Run into issues with HB 1445? or need to elaborate?', 'More Info (5)',\n",
      "       'Additional ideas for your comment (4)',\n",
      "       'Did you send a comment to your two Representatives about HB 1513?',\n",
      "       'Run into issues with HB 1513 or need to elaborate?', 'More Info (6)',\n",
      "       'Email link not work for you? (2)',\n",
      "       'Did you email the 16 committee members about HB&nbsp;2089?',\n",
      "       'Run into issues with HB&nbsp;2089 or need to elaborate?',\n",
      "       'More Info (7)', 'Email link not work for you? (3)',\n",
      "       'Did you email the 24 committee members about SB 5950?',\n",
      "       'Run into issues with SB 5950 or need to elaborate?', 'More Info (8)',\n",
      "       'Email link not work for you? (4)',\n",
      "       'Did you email the 24 committee members about SB 5949?',\n",
      "       'Run into issues with SB 5949 or need to elaborate?',\n",
      "       'Awesome, you did it! Thank you and please let us know if you had any issues.'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Determine the attribute columns starting from the 7th column (index 6)\n",
    "attribute_columns = df.columns[6:]\n",
    "\n",
    "# Ensure that we have the correct columns\n",
    "print(\"Attribute columns:\", attribute_columns)\n",
    "\n",
    "# Unpivot the DataFrame\n",
    "unpivoted_df = pd.melt(df, id_vars=df.columns[:6], value_vars=attribute_columns, var_name='Attribute', value_name='Value')\n",
    "\n",
    "# Convert 'Attribute' to a categorical type to maintain the order dynamically\n",
    "unpivoted_df['Attribute'] = pd.Categorical(unpivoted_df['Attribute'], categories=attribute_columns, ordered=True)\n",
    "\n",
    "# Sort by 'ID' and the categorical 'Attribute' to maintain the sequence and reset index\n",
    "unpivoted_df = unpivoted_df.sort_values(['Email', 'Attribute']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'Key ID' column by concatenating 'Submission ID' + a number in the format of 01, 02, 03, etc.\n",
    "\n",
    "# Create the 'Key ID' column with the formatted string\n",
    "unpivoted_df.insert(0, 'Key ID', unpivoted_df.groupby('Submission ID').cumcount() + 1)\n",
    "\n",
    "# Concatenate 'Submission ID' to the 'Key ID' two-digit number with leading zeros\n",
    "unpivoted_df['Key ID'] = unpivoted_df['Submission ID'] + unpivoted_df['Key ID'].apply(lambda x: f\"{x:02}\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "# print(unpivoted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the action numbers\n",
    "action_numbers = []\n",
    "\n",
    "# Iterate over each group in the DataFrame based on 'Submission ID'\n",
    "for _, group in unpivoted_df.groupby('Submission ID'):\n",
    "    # Initialize action number counter for each group\n",
    "    action_number = 1\n",
    "    \n",
    "    # Iterate through the 'Attribute' column in the group\n",
    "    for attribute in group['Attribute']:\n",
    "        # Check if the current attribute contains 'Response_Count' or 'Submitted at'\n",
    "        if 'Response_Count' in attribute or 'Submitted at' in attribute:\n",
    "            # Append None to action_numbers if condition is met\n",
    "            action_numbers.append(None)\n",
    "        else:\n",
    "            # Append the current action number to the list\n",
    "            action_numbers.append(action_number)\n",
    "            \n",
    "            # Check if the current attribute marks the end of a subgroup\n",
    "            if 'Run into issues with' in attribute:\n",
    "                # Increment the action number for the next subgroup\n",
    "                action_number += 1\n",
    "\n",
    "# Assign the list of action numbers to the new 'Action Number' column in the DataFrame\n",
    "unpivoted_df['Action Number'] = action_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "csv_path = r'D:\\Users\\peter\\PythonProjects\\PandasTest\\data\\Week 05 Sun_normalized.csv'\n",
    "\n",
    "# Write DataFrame to CSV file\n",
    "unpivoted_df.to_csv(csv_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
